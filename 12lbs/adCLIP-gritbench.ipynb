{"cells":[{"cell_type":"markdown","metadata":{"id":"oZfQWEvM1rcP"},"source":["# Adapting-CLIP"]},{"cell_type":"code","execution_count":12,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":1584,"status":"ok","timestamp":1681796974509,"user":{"displayName":"Jay Suh","userId":"06534266656340944442"},"user_tz":300},"id":"QGpcZ9Fn16NX","outputId":"37f3c73f-814d-458e-df52-4ec14260f526"},"outputs":[{"name":"stdout","output_type":"stream","text":["Drive already mounted at /content/drive/; to attempt to forcibly remount, call drive.mount(\"/content/drive/\", force_remount=True).\n"]}],"source":["######## Mount the drive ########\n","from google.colab import drive\n","drive.mount('/content/drive/')\n","\n","######## DIRPATH ########\n","DIRPATH_GRIT = '/content/drive/MyDrive/grit_official/'\n","DIRPATH_DATA = os.path.join(DIRPATH_GRIT, 'data/downloaded_logs/default_job/data/downloaded/GRIT/')\n","DIRPATH_LOCAL = '/content/GRIT-LOCAL/'"]},{"cell_type":"code","execution_count":4,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":10920,"status":"ok","timestamp":1681795854263,"user":{"displayName":"Jay Suh","userId":"06534266656340944442"},"user_tz":300},"id":"Z77wG6jO1rcR","outputId":"ef540a60-d250-42b3-d999-2c9893880f08"},"outputs":[{"name":"stdout","output_type":"stream","text":["Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n","Collecting ftfy\n","  Downloading ftfy-6.1.1-py3-none-any.whl (53 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m53.1/53.1 kB\u001b[0m \u001b[31m4.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: regex in /usr/local/lib/python3.9/dist-packages (2022.10.31)\n","Requirement already satisfied: tqdm in /usr/local/lib/python3.9/dist-packages (4.65.0)\n","Requirement already satisfied: wcwidth>=0.2.5 in /usr/local/lib/python3.9/dist-packages (from ftfy) (0.2.6)\n","Installing collected packages: ftfy\n","Successfully installed ftfy-6.1.1\n","Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n","Collecting git+https://github.com/openai/CLIP.git\n","  Cloning https://github.com/openai/CLIP.git to /tmp/pip-req-build-k3r8ypiq\n","  Running command git clone --filter=blob:none --quiet https://github.com/openai/CLIP.git /tmp/pip-req-build-k3r8ypiq\n","  Resolved https://github.com/openai/CLIP.git to commit a9b1bf5920416aaeaec965c25dd9e8f98c864f16\n","  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n","Requirement already satisfied: ftfy in /usr/local/lib/python3.9/dist-packages (from clip==1.0) (6.1.1)\n","Requirement already satisfied: regex in /usr/local/lib/python3.9/dist-packages (from clip==1.0) (2022.10.31)\n","Requirement already satisfied: tqdm in /usr/local/lib/python3.9/dist-packages (from clip==1.0) (4.65.0)\n","Requirement already satisfied: torch in /usr/local/lib/python3.9/dist-packages (from clip==1.0) (2.0.0+cu118)\n","Requirement already satisfied: torchvision in /usr/local/lib/python3.9/dist-packages (from clip==1.0) (0.15.1+cu118)\n","Requirement already satisfied: wcwidth>=0.2.5 in /usr/local/lib/python3.9/dist-packages (from ftfy->clip==1.0) (0.2.6)\n","Requirement already satisfied: sympy in /usr/local/lib/python3.9/dist-packages (from torch->clip==1.0) (1.11.1)\n","Requirement already satisfied: jinja2 in /usr/local/lib/python3.9/dist-packages (from torch->clip==1.0) (3.1.2)\n","Requirement already satisfied: typing-extensions in /usr/local/lib/python3.9/dist-packages (from torch->clip==1.0) (4.5.0)\n","Requirement already satisfied: networkx in /usr/local/lib/python3.9/dist-packages (from torch->clip==1.0) (3.1)\n","Requirement already satisfied: filelock in /usr/local/lib/python3.9/dist-packages (from torch->clip==1.0) (3.11.0)\n","Requirement already satisfied: triton==2.0.0 in /usr/local/lib/python3.9/dist-packages (from torch->clip==1.0) (2.0.0)\n","Requirement already satisfied: lit in /usr/local/lib/python3.9/dist-packages (from triton==2.0.0->torch->clip==1.0) (16.0.1)\n","Requirement already satisfied: cmake in /usr/local/lib/python3.9/dist-packages (from triton==2.0.0->torch->clip==1.0) (3.25.2)\n","Requirement already satisfied: requests in /usr/local/lib/python3.9/dist-packages (from torchvision->clip==1.0) (2.27.1)\n","Requirement already satisfied: numpy in /usr/local/lib/python3.9/dist-packages (from torchvision->clip==1.0) (1.22.4)\n","Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /usr/local/lib/python3.9/dist-packages (from torchvision->clip==1.0) (8.4.0)\n","Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.9/dist-packages (from jinja2->torch->clip==1.0) (2.1.2)\n","Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.9/dist-packages (from requests->torchvision->clip==1.0) (3.4)\n","Requirement already satisfied: charset-normalizer~=2.0.0 in /usr/local/lib/python3.9/dist-packages (from requests->torchvision->clip==1.0) (2.0.12)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.9/dist-packages (from requests->torchvision->clip==1.0) (2022.12.7)\n","Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.9/dist-packages (from requests->torchvision->clip==1.0) (1.26.15)\n","Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.9/dist-packages (from sympy->torch->clip==1.0) (1.3.0)\n","Building wheels for collected packages: clip\n","  Building wheel for clip (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for clip: filename=clip-1.0-py3-none-any.whl size=1369398 sha256=0a897e131b73abb2f55115ed350f467f81ec8f56d16e3411ad59af27d6ad15b7\n","  Stored in directory: /tmp/pip-ephem-wheel-cache-61hap9xj/wheels/c8/e4/e1/11374c111387672fc2068dfbe0d4b424cb9cdd1b2e184a71b5\n","Successfully built clip\n","Installing collected packages: clip\n","Successfully installed clip-1.0\n"]}],"source":["######## Install the dependencies ########\n","!pip install ftfy regex tqdm\n","!pip install git+https://github.com/openai/CLIP.git"]},{"cell_type":"code","execution_count":18,"metadata":{"executionInfo":{"elapsed":194,"status":"ok","timestamp":1681797794759,"user":{"displayName":"Jay Suh","userId":"06534266656340944442"},"user_tz":300},"id":"7eSy5fJ51rcS"},"outputs":[],"source":["import os\n","import json\n","from PIL import Image"]},{"cell_type":"markdown","metadata":{"id":"6nWCBOVp1rcS"},"source":["## Load images from Google Drive "]},{"cell_type":"code","execution_count":7,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":400342,"status":"ok","timestamp":1681796546283,"user":{"displayName":"Jay Suh","userId":"06534266656340944442"},"user_tz":300},"id":"j_YBVWJk1rcS","outputId":"11b0b47a-f3c9-42c5-d374-eb11f8ba310e"},"outputs":[{"name":"stdout","output_type":"stream","text":["/content\n"]}],"source":["# Load GRIT data\n","if(not os.path.exists(DIRPATH_LOCAL)):\n","    os.makedirs(DIRPATH_LOCAL)\n","    %cd /content/\n","    !cp /content/drive/MyDrive/COLAB-FILES/12lbs/grit_local.tar.gz /content/\n","    !tar -xzf grit_local.tar.gz    "]},{"cell_type":"code","execution_count":9,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":12178,"status":"ok","timestamp":1681796710121,"user":{"displayName":"Jay Suh","userId":"06534266656340944442"},"user_tz":300},"id":"juVF9oT_1rcT","outputId":"63cea9d8-47c6-4bae-bf48-562c61357aa4"},"outputs":[{"name":"stdout","output_type":"stream","text":["/content/drive/MyDrive/adapting-CLIP\n"]}],"source":["%cd /content/drive/MyDrive/adapting-CLIP/\n","\n","#import argparse\n","#import os.path as osp\n","from tqdm import tqdm\n","import numpy as np\n","import torch\n","from models.slic_vit import SLICViT\n","from models.ss_baseline import SSBaseline\n","from models.resnet_high_res import ResNetHighRes\n","from utils.zsg_data import FlickrDataset, VGDataset\n","from utils.grounding_evaluator import GroundingEvaluator"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":398},"executionInfo":{"elapsed":10289,"status":"ok","timestamp":1681799865613,"user":{"displayName":"Jay Suh","userId":"06534266656340944442"},"user_tz":300},"id":"hNqOBWim3Uyg","outputId":"eb018935-9964-43ba-8fa9-89133502fe84"},"outputs":[],"source":["# ! python eval.py --model vit14 --dataset flickr_s1_val --iou_thr 0.5 --num_samples 500\n","\n","model = SLICViT\n","args = {\n","    'model': 'vit14',\n","    'alpha': 0.75,\n","    'aggregation': 'mean',\n","    'n_segments': list(range(100, 601, 50)),\n","    'temperature': 0.02,\n","    'upsample': 2,\n","    'start_block': 0,\n","    'compactness': 50,\n","    'sigma': 0,\n","}\n","dataset_full = FlickrDataset(data_type='flickr30k_c1/val')\n","model = model(**args).cuda()\n","#model.eval()"]},{"cell_type":"markdown","metadata":{"id":"SgKMHpBv5qvl"},"source":["## Load json file"]},{"cell_type":"code","execution_count":15,"metadata":{"executionInfo":{"elapsed":1360,"status":"ok","timestamp":1681797004100,"user":{"displayName":"Jay Suh","userId":"06534266656340944442"},"user_tz":300},"id":"tu6XD7YC3YuY"},"outputs":[],"source":["# Chekc the images in the json file\n","with open(os.path.join(DIRPATH_DATA,'samples/ablation/localization.json')) as f:\n","    data = json.load(f)\n","\n","    # Example of the json element\n","    # [\n","    #     {\n","    #         \"example_id\": \"coco_loc_test-reserve_spoon_527067\",\n","    #         \"image_id\": \"coco/test2015/COCO_test2015_000000527067.jpg\",\n","    #         \"output_options\": null,\n","    #         \"task_bbox\": null,\n","    #         \"task_name\": \"localization\",\n","    #         \"task_query\": \"spoon\"\n","    #     },\n","    #     ... \n","    # ]"]},{"cell_type":"code","execution_count":16,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":579,"status":"ok","timestamp":1681797008648,"user":{"displayName":"Jay Suh","userId":"06534266656340944442"},"user_tz":300},"id":"Q4kEK0Ko54rJ","outputId":"f1805d78-fb82-4d83-bc72-10716bf33548"},"outputs":[{"name":"stdout","output_type":"stream","text":["21078\n","ALL THE IMAGES EXISTING -  True 21078 21078\n"]},{"data":{"text/plain":["{'coco/test2015',\n"," 'distorted/localization/coco/test2015',\n"," 'nyuv2',\n"," 'open_images/test'}"]},"execution_count":16,"metadata":{},"output_type":"execute_result"}],"source":["# Check the number of the images\n","print(len(data))\n","\n","# Check if the images are in the folder using vectorization\n","def checkfile(di):\n","  return os.path.exists(os.path.join(DIRPATH_LOCAL,'images',di['image_id']))\n","cnt = len(list(filter(checkfile,data)))\n","print(\"ALL THE IMAGES EXISTING - \",cnt==len(data),cnt,len(data))\n","\n","# Check the types of the images need to be downloaded\n","folderset=set({})\n","for di in data:\n","  folderset.add(\"/\".join(di['image_id'].split('/')[:-1]))\n","  # check if the image exists\n","folderset"]},{"attachments":{},"cell_type":"markdown","metadata":{},"source":["## Evaluate the model on the GRIT-Bench dataset"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"w80LaPhq50eR","outputId":"eb028b48-50ba-42b2-a7a6-eebcbec89254"},"outputs":[{"name":"stderr","output_type":"stream","text":["  1%|          | 108/21078 [06:52<22:09:33,  3.80s/it]"]}],"source":["## Predict\n","output = []\n","# Output format example\n","# [\n","#    {\n","#        \"example_id\" : str\n","#        \"confidence\" : float in [0,1]\n","#        \"bboxes\"     : 2d list of int [[x1,y1,x2,y2],...] # box coordinates, per instance\n","#    },\n","#    ...\n","#]\n","for json_chunk in tqdm(data):\n","    image_path = os.path.join(DIRPATH_LOCAL,'images',json_chunk['image_id'])\n","    if(not os.path.exists(image_path)):\n","        print(\"Image not found - \",image_path)\n","        break\n","\n","    # Load the image\n","    image = np.array(Image.open(image_path).convert(\"RGB\"))\n","    # Load the text\n","    text = json_chunk['task_query']\n","    \n","    # Predict\n","    pred_boxes, _ = model(image, text)\n","\n","    # Append the result\n","    output_chunk = {\n","        \"example_id\" : json_chunk['example_id'],\n","        \"confidence\" : 0.5, #float(pred_scores.mean()),\n","        \"bboxes\"     : pred_boxes.tolist()\n","    }\n","    output.append(output_chunk)\n","\n","    # Save the intermediate results\n","    if(len(output)%500==0):\n","        OUTPUT_FILENAME = f'/content/drive/MyDrive/COLAB-FILES/12lbs/jsonfiles/ablation_localization_{len(output)//500}.json'\n","        with open(OUTPUT_FILENAME, 'w') as f:\n","            json.dump(output, f)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"WoJ99WcKHs2d"},"outputs":[],"source":["OUTPUT_FILENAME = '/content/drive/MyDrive/COLAB-FILES/12lbs/localization.json'\n","with open(OUTPUT_FILENAME, 'w') as f:\n","    json.dump(output, f)"]},{"cell_type":"code","execution_count":25,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":587,"status":"ok","timestamp":1681798462308,"user":{"displayName":"Jay Suh","userId":"06534266656340944442"},"user_tz":300},"id":"4pBEltxi9qUA","outputId":"162a2e6b-be45-44c0-a304-4f717c5fba26"},"outputs":[{"name":"stdout","output_type":"stream","text":["Total Parameters: 428402945\n","Trainable Parameters: 428402945\n"]}],"source":["# Count the number of the pparameters(need for the GRIT submission)\n","\n","total_params = sum(p.numel() for p in model.parameters())\n","trainable_params = sum(p.numel() for p in model.parameters() if p.requires_grad)\n","\n","print(f\"Total Parameters: {total_params}\")\n","print(f\"Trainable Parameters: {trainable_params}\")"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"2JSLn8YNHpeg"},"outputs":[],"source":[]}],"metadata":{"accelerator":"GPU","colab":{"gpuType":"A100","provenance":[]},"gpuClass":"standard","kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"},"orig_nbformat":4},"nbformat":4,"nbformat_minor":0}
