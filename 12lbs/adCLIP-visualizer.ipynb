{"cells":[{"cell_type":"markdown","metadata":{"id":"PHz4ELWvnKQh"},"source":["[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/jayhansuh/COLAB-FILES/blob/main/12lbs/adCLIP-visualizer.ipynb)"]},{"cell_type":"markdown","metadata":{"id":"Zx0g1YT8vps_"},"source":["# Adapting CLIP model"]},{"cell_type":"code","execution_count":1,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":15217,"status":"ok","timestamp":1681876139667,"user":{"displayName":"Jay Suh","userId":"06534266656340944442"},"user_tz":300},"id":"iuYG3ZEXvgia","outputId":"1e73b262-6268-42ae-fac9-5260df55a557"},"outputs":[{"name":"stdout","output_type":"stream","text":["Drive already mounted at /content/drive/; to attempt to forcibly remount, call drive.mount(\"/content/drive/\", force_remount=True).\n","/content/drive/MyDrive/adapting-CLIP\n","Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n","Requirement already satisfied: ftfy in /usr/local/lib/python3.9/dist-packages (6.1.1)\n","Requirement already satisfied: regex in /usr/local/lib/python3.9/dist-packages (2022.10.31)\n","Requirement already satisfied: tqdm in /usr/local/lib/python3.9/dist-packages (4.65.0)\n","Requirement already satisfied: wcwidth>=0.2.5 in /usr/local/lib/python3.9/dist-packages (from ftfy) (0.2.6)\n","Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n","Collecting git+https://github.com/openai/CLIP.git\n","  Cloning https://github.com/openai/CLIP.git to /tmp/pip-req-build-qpq27men\n","  Running command git clone --filter=blob:none --quiet https://github.com/openai/CLIP.git /tmp/pip-req-build-qpq27men\n","  Resolved https://github.com/openai/CLIP.git to commit a9b1bf5920416aaeaec965c25dd9e8f98c864f16\n","  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n","Requirement already satisfied: ftfy in /usr/local/lib/python3.9/dist-packages (from clip==1.0) (6.1.1)\n","Requirement already satisfied: regex in /usr/local/lib/python3.9/dist-packages (from clip==1.0) (2022.10.31)\n","Requirement already satisfied: tqdm in /usr/local/lib/python3.9/dist-packages (from clip==1.0) (4.65.0)\n","Requirement already satisfied: torch in /usr/local/lib/python3.9/dist-packages (from clip==1.0) (2.0.0+cu118)\n","Requirement already satisfied: torchvision in /usr/local/lib/python3.9/dist-packages (from clip==1.0) (0.15.1+cu118)\n","Requirement already satisfied: wcwidth>=0.2.5 in /usr/local/lib/python3.9/dist-packages (from ftfy->clip==1.0) (0.2.6)\n","Requirement already satisfied: networkx in /usr/local/lib/python3.9/dist-packages (from torch->clip==1.0) (3.1)\n","Requirement already satisfied: jinja2 in /usr/local/lib/python3.9/dist-packages (from torch->clip==1.0) (3.1.2)\n","Requirement already satisfied: typing-extensions in /usr/local/lib/python3.9/dist-packages (from torch->clip==1.0) (4.5.0)\n","Requirement already satisfied: triton==2.0.0 in /usr/local/lib/python3.9/dist-packages (from torch->clip==1.0) (2.0.0)\n","Requirement already satisfied: filelock in /usr/local/lib/python3.9/dist-packages (from torch->clip==1.0) (3.11.0)\n","Requirement already satisfied: sympy in /usr/local/lib/python3.9/dist-packages (from torch->clip==1.0) (1.11.1)\n","Requirement already satisfied: lit in /usr/local/lib/python3.9/dist-packages (from triton==2.0.0->torch->clip==1.0) (16.0.1)\n","Requirement already satisfied: cmake in /usr/local/lib/python3.9/dist-packages (from triton==2.0.0->torch->clip==1.0) (3.25.2)\n","Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /usr/local/lib/python3.9/dist-packages (from torchvision->clip==1.0) (8.4.0)\n","Requirement already satisfied: numpy in /usr/local/lib/python3.9/dist-packages (from torchvision->clip==1.0) (1.22.4)\n","Requirement already satisfied: requests in /usr/local/lib/python3.9/dist-packages (from torchvision->clip==1.0) (2.27.1)\n","Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.9/dist-packages (from jinja2->torch->clip==1.0) (2.1.2)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.9/dist-packages (from requests->torchvision->clip==1.0) (2022.12.7)\n","Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.9/dist-packages (from requests->torchvision->clip==1.0) (1.26.15)\n","Requirement already satisfied: charset-normalizer~=2.0.0 in /usr/local/lib/python3.9/dist-packages (from requests->torchvision->clip==1.0) (2.0.12)\n","Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.9/dist-packages (from requests->torchvision->clip==1.0) (3.4)\n","Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.9/dist-packages (from sympy->torch->clip==1.0) (1.3.0)\n"]}],"source":["######## Mount the drive ########\n","\n","from google.colab import drive\n","drive.mount('/content/drive/')\n","%cd /content/drive/MyDrive/adapting-CLIP\n","#%cd ../../adapting-CLIP\n","\n","######## Install the dependencies ########\n","!pip install ftfy regex tqdm\n","!pip install git+https://github.com/openai/CLIP.git"]},{"cell_type":"code","execution_count":27,"metadata":{"executionInfo":{"elapsed":90,"status":"ok","timestamp":1681877815703,"user":{"displayName":"Jay Suh","userId":"06534266656340944442"},"user_tz":300},"id":"VQFvAPnYv0DS"},"outputs":[],"source":["#import argparse\n","#import os.path as osp\n","import os, json\n","from tqdm import tqdm\n","import numpy as np\n","import torch\n","from models.slic_vit import SLICViT\n","from models.ss_baseline import SSBaseline\n","from models.resnet_high_res import ResNetHighRes\n","from utils.zsg_data import FlickrDataset, VGDataset\n","from utils.grounding_evaluator import GroundingEvaluator\n","\n","import matplotlib.pyplot as plt\n","import matplotlib.patches as patches\n","import cv2\n","import random\n","%matplotlib inline"]},{"cell_type":"code","execution_count":3,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":20748,"status":"ok","timestamp":1681876164662,"user":{"displayName":"Jay Suh","userId":"06534266656340944442"},"user_tz":300},"id":"1SlNWvg7v3wm","outputId":"78ee0f5c-27bb-4e02-8b63-34230ac0abfb"},"outputs":[{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.9/dist-packages/torch/nn/functional.py:3737: UserWarning: nn.functional.upsample is deprecated. Use nn.functional.interpolate instead.\n","  warnings.warn(\"nn.functional.upsample is deprecated. Use nn.functional.interpolate instead.\")\n"]}],"source":["# ! python eval.py --model vit14 --dataset flickr_s1_val --iou_thr 0.5 --num_samples 500\n","\n","model = SLICViT\n","args = {\n","    'model': 'vit14',\n","    'alpha': 0.75,\n","    'aggregation': 'mean',\n","    'n_segments': list(range(100, 601, 50)),\n","    'temperature': 0.02,\n","    'upsample': 2,\n","    'start_block': 0,\n","    'compactness': 50,\n","    'sigma': 0,\n","}\n","dataset_full = FlickrDataset(data_type='flickr30k_c1/val')\n","iou_thr = 0.5\n","model = model(**args).cuda()"]},{"cell_type":"code","execution_count":5,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":84844,"status":"ok","timestamp":1681876471939,"user":{"displayName":"Jay Suh","userId":"06534266656340944442"},"user_tz":300},"id":"R6Y1Uat_wJ36","outputId":"2cf97df1-1f53-4813-c2a1-7e44816cbb52"},"outputs":[{"name":"stderr","output_type":"stream","text":["100%|██████████| 16/16 [01:24<00:00,  5.28s/it]"]},{"name":"stdout","output_type":"stream","text":["\n","Acc: 0.1875\n"]},{"name":"stderr","output_type":"stream","text":["\n"]}],"source":["######### Evaluate the model #########\n","# Randomly select images\n","num_samples = 16\n","idxs = random.sample(range(len(dataset_full)), num_samples)\n","\n","# Create a random subset of the dataset\n","dataset = FlickrDataset(data_type=dataset_full.data_type)\n","dataset.image_paths = [dataset_full.image_paths[idx] for idx in idxs]\n","dataset.bboxes = [dataset_full.bboxes[idx] for idx in idxs]\n","dataset.phrases = [dataset_full.phrases[idx] for idx in idxs]\n","\n","# Lists to hold loaded data\n","imgs = []\n","texts = []\n","bbox_gts = []\n","bbox_preds = []\n","\n","# Predict the bounding boxes\n","for idx in tqdm(range(len(dataset))):\n","\n","    # Data loading - do not call __getitem__ repeatedly\n","    data = dataset[idx] \n","    #print(data['edge_box'])\n","    im = data['image']\n","    text = data['phrases'][0]\n","    bbox_gts.append(data['bbox'])\n","\n","    # Predict\n","    bbox_pred, _ = model(im, text)\n","\n","    # Hold loaded data\n","    imgs.append(im)\n","    texts.append(text)\n","    bbox_preds.append(bbox_pred[0])\n","\n","# Evaluate the model\n","evaluator = GroundingEvaluator(gt_dataset=dataset, iou_thresh=iou_thr)\n","acc = evaluator(torch.from_numpy(np.stack(bbox_preds, axis=0)))\n","print('\\nAcc: {}'.format(acc))"]},{"cell_type":"code","execution_count":6,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":1000,"output_embedded_package_id":"1-3NoqL5gGX8Iz0F6pkbD2t76QKmH1Gy6"},"executionInfo":{"elapsed":5450,"status":"ok","timestamp":1681876684265,"user":{"displayName":"Jay Suh","userId":"06534266656340944442"},"user_tz":300},"id":"9pGh5AHIwMci","outputId":"0a2642d2-69f0-4f04-d647-fcb543eb1b73"},"outputs":[{"data":{"text/plain":["Output hidden; open in https://colab.research.google.com to view."]},"metadata":{},"output_type":"display_data"}],"source":["######## Visualize multiple images in Grid ########\n","\n","# Set the number of rows and columns in the grid\n","row_num = num_samples // 4 + (1 if num_samples % 4 != 0 else 0)\n","row_num = max(row_num, 2) # at least 2 rows\n","col_num = 4\n","\n","# Red: predicted bounding box\n","# Blue: ground truth bounding box\n","fig, axs = plt.subplots(row_num, col_num, figsize=(20, 20))\n","for i in range(row_num):\n","    for j in range(col_num):\n","\n","        idx = i * col_num + j\n","\n","        # check if the index is out of range\n","        if(idx<num_samples):\n","          im = imgs[idx]\n","          bbox_pred = bbox_preds[idx]\n","          bbox_gt = bbox_gts[idx]\n","\n","          im = cv2.rectangle(im, (int(bbox_pred[0]), int(bbox_pred[1])), (int(bbox_pred[2]), int(bbox_pred[3])), (255, 50, 50), 2)\n","          im = cv2.rectangle(im, (int(bbox_gt[0]), int(bbox_gt[1])), (int(bbox_gt[2]), int(bbox_gt[3])), (50, 50, 255), 2)\n","          \n","          axs[i, j].imshow(im)\n","          axs[i, j].set_title(texts[idx])\n","\n","        # remove the axis\n","        axs[i, j].axis('off')\n","\n","plt.show()\n","\n","# Show the text\n","# print(texts)\n"]},{"cell_type":"markdown","metadata":{"id":"mtzNC42QzQAy"},"source":["# Export the sampled images and a json file"]},{"cell_type":"code","execution_count":31,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":93,"status":"ok","timestamp":1681877875026,"user":{"displayName":"Jay Suh","userId":"06534266656340944442"},"user_tz":300},"id":"NIk25QqBBrFa","outputId":"b0c33998-c174-432f-a384-dc874e64a4f3"},"outputs":[{"data":{"text/plain":["{'7173663269.jpg': (['two older folks'], [152, 100, 273, 228]),\n"," '226115048.jpg': (['a beer'], [112, 220, 152, 299]),\n"," '3782318456.jpg': (['equipment'], [3, 122, 491, 500]),\n"," '3517370470.jpg': (['one'], [152, 113, 267, 428]),\n"," '3329777647.jpg': (['a ball'], [363, 217, 401, 245]),\n"," '543603259.jpg': (['a wall'], [203, 130, 339, 425]),\n"," '4776990069.jpg': (['a carousel'], [146, 167, 394, 375]),\n"," '4756254503.jpg': (['two ice cream cones'], [147, 138, 206, 182]),\n"," '217108448.jpg': (['a telescope'], [113, 109, 287, 478]),\n"," '2534137886.jpg': (['a heavy bucket'], [188, 201, 364, 311]),\n"," '2620517927.jpg': (['motorcycles'], [46, 238, 288, 307]),\n"," '1045521051.jpg': (['the TV'], [44, 11, 171, 153]),\n"," '186487635.jpg': (['a wall'], [248, 11, 352, 475]),\n"," '3407528957.jpg': (['a table'], [155, 243, 472, 334]),\n"," '7573421864.jpg': (['leopard print paper'], [64, 18, 278, 487]),\n"," '3393035454.jpg': (['a tan rock'], [268, 291, 355, 383])}"]},"execution_count":31,"metadata":{},"output_type":"execute_result"}],"source":["# Make a dictionary of image file name -> (text, bbox_gt)\n","flickrExamples = dict(zip(dataset.image_paths,list(zip(dataset.phrases,bbox_gts))))\n","flickrExamples"]},{"cell_type":"code","execution_count":32,"metadata":{"executionInfo":{"elapsed":90,"status":"ok","timestamp":1681877876630,"user":{"displayName":"Jay Suh","userId":"06534266656340944442"},"user_tz":300},"id":"8gcIjtnxoDnA"},"outputs":[],"source":["# Export the dictionary to a json file\n","with open(\"/content/drive/MyDrive/COLAB-FILES/flickr-examples.json\", 'w') as f:\n","    json.dump(flickrExamples, f,indent=2)"]},{"cell_type":"code","execution_count":33,"metadata":{"executionInfo":{"elapsed":1292,"status":"ok","timestamp":1681877878191,"user":{"displayName":"Jay Suh","userId":"06534266656340944442"},"user_tz":300},"id":"RrCGbLJsrzlO"},"outputs":[],"source":["# Copy example images in the flickr-examples directory\n","example_dir = \"/content/drive/MyDrive/COLAB-FILES/flickr-examples\"\n","if(not os.path.exists(example_dir)):\n","    os.mkdir(example_dir)\n","for impath in dataset.image_paths:\n","    imname = impath.split(\"/\")[-1]\n","    source =os.path.join(dataset.image_dir,impath)\n","    target = os.path.join(example_dir, imname)\n","    os.system(\"cp {} {}\".format(source,target))"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"88CGTi8dspW-"},"outputs":[],"source":[]}],"metadata":{"accelerator":"GPU","colab":{"gpuType":"V100","provenance":[],"toc_visible":true},"gpuClass":"standard","kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"}},"nbformat":4,"nbformat_minor":0}
